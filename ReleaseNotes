Dear users,

LizardFS 3.10.0 is now stable.

The package consists of:
 - erasure code goals (aka K+M goals)
 - per directory quotas
 - improved interaction with legacy chunkservers and mounts
 - ports for OSX and FreeBSD
 - updated mfsfileinfo output with xor/ec goals
 - many fixes

Details:

Erasure code goals

For each file using ec(K+M) goal, the system will split the file into K parts and generate M parity parts. Any K parts are required to be able to reproduce file contents.

If labels are specified, parts will be kept on chunkservers with these labels. Otherwise, default wildcard labels will be used.

This kind of goal allows M of K+M copies to be lost and the file would still remain accessible. Erasure code goal occupies M/K extra space.

Erasure code goals are in rc version right now and they are here for peer review - please share your opinions and test results with us.

Please note that minimal K value is 2 and minimal M value is 1.

Examples of new goal configuration:
5 ec32 : $ec(3,2){ A B _ _ _ }
6 ec43 : $ec(4,3)


Per directory quotas

It is now possible to set inode/size limits per directory.
In case of multiple quota rules, the most restrictive one is always effective.
Example:

mfssetquota -d 10M 100M 50M 1G /mnt/lizardfs/a/directory

Improved interaction with legacy chunkservers and mounts

Pre-2.6.0 mounts and chunkservers used to be not fully compatible with 3.9.x servers, which complicated the upgrade process. Those issues are now solved - new mounts are perfectly capable of communicating with legacy chunkservers and vice versa.
This rule has one exception: for consistency reasons, replication from new chunkservers to old ones is disabled.


Ports for OSX and FreeBSD

LizardFS is now buildable for those systems.


Fixes

 - denying replication during scan
 - atomicity of replication process
 - sending proper error codes to master
 - proper handling of replication limits during rebalancing
 - removal of splice call
 - removing possible livelock in master networking
 - ading missing update in inodes id pool

Next release (unstable now) will contain a massive set of patches which make the cluster more responsive.
Also, a great reduction of master's and chunkserver's RAM usage is to be expected (at least 30% less resources needed).
An improved client tool for managing goals/quotas/files etc. is coming as well.

Best,
Piotr Sarna
LizardFS Team
